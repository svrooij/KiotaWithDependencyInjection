// <auto-generated/>
using Microsoft.Kiota.Abstractions.Serialization;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System;
namespace Spotify.Models {
    public class AudioAnalysisObject_track : IAdditionalDataHolder, IParsable 
    {
        /// <summary>Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.</summary>
        public IDictionary<string, object> AdditionalData { get; set; }
        /// <summary>The number of channels used for analysis. If 1, all channels are summed together to mono before analysis.</summary>
        public int? AnalysisChannels { get; set; }
        /// <summary>The sample rate used to decode and analyze this track. May differ from the actual sample rate of this track available on Spotify.</summary>
        public int? AnalysisSampleRate { get; set; }
        /// <summary>An [Echo Nest Musical Fingerprint (ENMFP)](https://academiccommons.columbia.edu/doi/10.7916/D8Q248M4) codestring for this track.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Codestring { get; set; }
#nullable restore
#else
        public string Codestring { get; set; }
#endif
        /// <summary>A version number for the Echo Nest Musical Fingerprint format used in the codestring field.</summary>
        public double? CodeVersion { get; set; }
        /// <summary>Length of the track in seconds.</summary>
        public double? Duration { get; set; }
        /// <summary>An [EchoPrint](https://github.com/spotify/echoprint-codegen) codestring for this track.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Echoprintstring { get; set; }
#nullable restore
#else
        public string Echoprintstring { get; set; }
#endif
        /// <summary>A version number for the EchoPrint format used in the echoprintstring field.</summary>
        public double? EchoprintVersion { get; set; }
        /// <summary>The time, in seconds, at which the track&apos;s fade-in period ends. If the track has no fade-in, this will be 0.0.</summary>
        public double? EndOfFadeIn { get; set; }
        /// <summary>The key the track is in. Integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class). E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.</summary>
        public int? Key { get; set; }
        /// <summary>The confidence, from 0.0 to 1.0, of the reliability of the `key`.</summary>
        public double? KeyConfidence { get; set; }
        /// <summary>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.</summary>
        public float? Loudness { get; set; }
        /// <summary>Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.</summary>
        public int? Mode { get; set; }
        /// <summary>The confidence, from 0.0 to 1.0, of the reliability of the `mode`.</summary>
        public double? ModeConfidence { get; set; }
        /// <summary>The exact number of audio samples analyzed from this track. See also `analysis_sample_rate`.</summary>
        public int? NumSamples { get; set; }
        /// <summary>An offset to the start of the region of the track that was analyzed. (As the entire track is analyzed, this should always be 0.)</summary>
        public int? OffsetSeconds { get; set; }
        /// <summary>A Rhythmstring for this track. The format of this string is similar to the Synchstring.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Rhythmstring { get; set; }
#nullable restore
#else
        public string Rhythmstring { get; set; }
#endif
        /// <summary>A version number for the Rhythmstring used in the rhythmstring field.</summary>
        public double? RhythmVersion { get; set; }
        /// <summary>This field will always contain the empty string.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? SampleMd5 { get; set; }
#nullable restore
#else
        public string SampleMd5 { get; set; }
#endif
        /// <summary>The time, in seconds, at which the track&apos;s fade-out period starts. If the track has no fade-out, this should match the track&apos;s length.</summary>
        public double? StartOfFadeOut { get; set; }
        /// <summary>A [Synchstring](https://github.com/echonest/synchdata) for this track.</summary>
#if NETSTANDARD2_1_OR_GREATER || NETCOREAPP3_1_OR_GREATER
#nullable enable
        public string? Synchstring { get; set; }
#nullable restore
#else
        public string Synchstring { get; set; }
#endif
        /// <summary>A version number for the Synchstring used in the synchstring field.</summary>
        public double? SynchVersion { get; set; }
        /// <summary>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.</summary>
        public float? Tempo { get; set; }
        /// <summary>The confidence, from 0.0 to 1.0, of the reliability of the `tempo`.</summary>
        public double? TempoConfidence { get; set; }
        /// <summary>An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of &quot;3/4&quot;, to &quot;7/4&quot;.</summary>
        public int? TimeSignature { get; set; }
        /// <summary>The confidence, from 0.0 to 1.0, of the reliability of the `time_signature`.</summary>
        public double? TimeSignatureConfidence { get; set; }
        /// <summary>The length of the region of the track was analyzed, if a subset of the track was analyzed. (As the entire track is analyzed, this should always be 0.)</summary>
        public int? WindowSeconds { get; set; }
        /// <summary>
        /// Instantiates a new <see cref="AudioAnalysisObject_track"/> and sets the default values.
        /// </summary>
        public AudioAnalysisObject_track()
        {
            AdditionalData = new Dictionary<string, object>();
        }
        /// <summary>
        /// Creates a new instance of the appropriate class based on discriminator value
        /// </summary>
        /// <returns>A <see cref="AudioAnalysisObject_track"/></returns>
        /// <param name="parseNode">The parse node to use to read the discriminator value and create the object</param>
        public static AudioAnalysisObject_track CreateFromDiscriminatorValue(IParseNode parseNode)
        {
            _ = parseNode ?? throw new ArgumentNullException(nameof(parseNode));
            return new AudioAnalysisObject_track();
        }
        /// <summary>
        /// The deserialization information for the current model
        /// </summary>
        /// <returns>A IDictionary&lt;string, Action&lt;IParseNode&gt;&gt;</returns>
        public virtual IDictionary<string, Action<IParseNode>> GetFieldDeserializers()
        {
            return new Dictionary<string, Action<IParseNode>>
            {
                {"analysis_channels", n => { AnalysisChannels = n.GetIntValue(); } },
                {"analysis_sample_rate", n => { AnalysisSampleRate = n.GetIntValue(); } },
                {"code_version", n => { CodeVersion = n.GetDoubleValue(); } },
                {"codestring", n => { Codestring = n.GetStringValue(); } },
                {"duration", n => { Duration = n.GetDoubleValue(); } },
                {"echoprint_version", n => { EchoprintVersion = n.GetDoubleValue(); } },
                {"echoprintstring", n => { Echoprintstring = n.GetStringValue(); } },
                {"end_of_fade_in", n => { EndOfFadeIn = n.GetDoubleValue(); } },
                {"key", n => { Key = n.GetIntValue(); } },
                {"key_confidence", n => { KeyConfidence = n.GetDoubleValue(); } },
                {"loudness", n => { Loudness = n.GetFloatValue(); } },
                {"mode", n => { Mode = n.GetIntValue(); } },
                {"mode_confidence", n => { ModeConfidence = n.GetDoubleValue(); } },
                {"num_samples", n => { NumSamples = n.GetIntValue(); } },
                {"offset_seconds", n => { OffsetSeconds = n.GetIntValue(); } },
                {"rhythm_version", n => { RhythmVersion = n.GetDoubleValue(); } },
                {"rhythmstring", n => { Rhythmstring = n.GetStringValue(); } },
                {"sample_md5", n => { SampleMd5 = n.GetStringValue(); } },
                {"start_of_fade_out", n => { StartOfFadeOut = n.GetDoubleValue(); } },
                {"synch_version", n => { SynchVersion = n.GetDoubleValue(); } },
                {"synchstring", n => { Synchstring = n.GetStringValue(); } },
                {"tempo", n => { Tempo = n.GetFloatValue(); } },
                {"tempo_confidence", n => { TempoConfidence = n.GetDoubleValue(); } },
                {"time_signature", n => { TimeSignature = n.GetIntValue(); } },
                {"time_signature_confidence", n => { TimeSignatureConfidence = n.GetDoubleValue(); } },
                {"window_seconds", n => { WindowSeconds = n.GetIntValue(); } },
            };
        }
        /// <summary>
        /// Serializes information the current object
        /// </summary>
        /// <param name="writer">Serialization writer to use to serialize this model</param>
        public virtual void Serialize(ISerializationWriter writer)
        {
            _ = writer ?? throw new ArgumentNullException(nameof(writer));
            writer.WriteIntValue("analysis_channels", AnalysisChannels);
            writer.WriteIntValue("analysis_sample_rate", AnalysisSampleRate);
            writer.WriteStringValue("codestring", Codestring);
            writer.WriteDoubleValue("code_version", CodeVersion);
            writer.WriteDoubleValue("duration", Duration);
            writer.WriteStringValue("echoprintstring", Echoprintstring);
            writer.WriteDoubleValue("echoprint_version", EchoprintVersion);
            writer.WriteDoubleValue("end_of_fade_in", EndOfFadeIn);
            writer.WriteIntValue("key", Key);
            writer.WriteDoubleValue("key_confidence", KeyConfidence);
            writer.WriteFloatValue("loudness", Loudness);
            writer.WriteIntValue("mode", Mode);
            writer.WriteDoubleValue("mode_confidence", ModeConfidence);
            writer.WriteIntValue("num_samples", NumSamples);
            writer.WriteIntValue("offset_seconds", OffsetSeconds);
            writer.WriteStringValue("rhythmstring", Rhythmstring);
            writer.WriteDoubleValue("rhythm_version", RhythmVersion);
            writer.WriteStringValue("sample_md5", SampleMd5);
            writer.WriteDoubleValue("start_of_fade_out", StartOfFadeOut);
            writer.WriteStringValue("synchstring", Synchstring);
            writer.WriteDoubleValue("synch_version", SynchVersion);
            writer.WriteFloatValue("tempo", Tempo);
            writer.WriteDoubleValue("tempo_confidence", TempoConfidence);
            writer.WriteIntValue("time_signature", TimeSignature);
            writer.WriteDoubleValue("time_signature_confidence", TimeSignatureConfidence);
            writer.WriteIntValue("window_seconds", WindowSeconds);
            writer.WriteAdditionalData(AdditionalData);
        }
    }
}
